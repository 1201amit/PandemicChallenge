{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(lookback_days, total_rows, input_date,  dyn_df,  reg):\n",
    "    final_df = pd.DataFrame()\n",
    "    time = lookback_days\n",
    "    output_date = input_date\n",
    "    rows = total_rows\n",
    "    fields_npi = []\n",
    "    filenames = [\"c1_school_closing.csv\", \"c2_workplace_closing.csv\", \"c3_cancel_public_events.csv\",\n",
    "            \"c4_restrictions_on_gatherings.csv\", \"c5_close_public_transport.csv\", \"c6_stay_at_home_requirements.csv\", \"c7_movementrestrictions.csv\",\n",
    "            \"c8_internationaltravel.csv\", \"h1_public_information_campaigns.csv\",\"h2_testing_policy.csv\",\"h3_contact_tracing.csv\", \"h6_facial_coverings.csv\"]\n",
    "\n",
    "    for i in filenames:\n",
    "        fields_npi.append(i[:-4])\n",
    "        \n",
    "    count_npis = 0\n",
    "    for npi_file in filenames:\n",
    "        India = 0\n",
    "        count_npis += 1 \n",
    "        npi_df = pd.read_csv(os.path.join('timeseries', npi_file))\n",
    "        # first we need to convert the header date formats to more y -m - d format\n",
    "        headers = []\n",
    "        for header in npi_df:\n",
    "            headers.append(header)\n",
    "        for i in range(3,len(headers)):\n",
    "            dt = parse(headers[i])\n",
    "            headers[i] = dt.strftime('%Y-%m-%d')\n",
    "        npi_df.columns = headers\n",
    "        for region in npi_df['country_code']:\n",
    "            if region == reg:\n",
    "                break           \n",
    "            India += 1 \n",
    "\n",
    "        for column in range(1, 1+time):\n",
    "            new  = pd.Series([], dtype = 'float64')\n",
    "            current_date = output_date - datetime.timedelta(column)\n",
    "            for row in range(rows):\n",
    "                new_date = current_date - datetime.timedelta(row)\n",
    "                new[row] = npi_df.loc[India, str(new_date)]          \n",
    "\n",
    "            final_df.insert(time*(count_npis-1)+column-1, fields_npi[count_npis-1][:-4] + str(column), new)\n",
    "\n",
    "    index = pd.Series([], dtype = 'float64')\n",
    "    \n",
    "    current_dates = []\n",
    "    for row in range(rows):\n",
    "        new_date = output_date - datetime.timedelta(row)\n",
    "        index[row] = new_date\n",
    "        current_dates.append(new_date)\n",
    "    final_df.insert(0, 'current_date', index)\n",
    "    \n",
    "    dyn_df1 = dyn_df[dyn_df['Code']==reg]\n",
    "    dyn_df1 = dyn_df.set_index('Date', drop = True)\n",
    "    #print(dyn_df1)\n",
    "    for header in dyn_df1:\n",
    "        if header == 'Date' or header == \"Unnamed: 0\" or header == 'Code':\n",
    "            continue \n",
    "        new_1  = pd.Series([], dtype = 'float64')\n",
    "        for row in range(rows):\n",
    "                new_date = current_date - datetime.timedelta(row)\n",
    "                new_1[row] = dyn_df1.loc[str(new_date), header][1] \n",
    "        \n",
    "\n",
    "                \n",
    "        final_df.insert(final_df.shape[1], header , new_1) \n",
    "        \n",
    "    final_df.to_csv(os.path.join('data', 'final.csv'))      \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/meenakshi/pandemic/covid-xprize-master/predictors\n",
      "    current_date  c1_school_clo1  c1_school_clo2  c1_school_clo3  \\\n",
      "0     2020-12-01             0.0             0.0             0.0   \n",
      "1     2020-11-30             0.0             0.0             0.0   \n",
      "2     2020-11-29             0.0             0.0             0.0   \n",
      "3     2020-11-28             0.0             0.0             0.0   \n",
      "4     2020-11-27             0.0             0.0             0.0   \n",
      "..           ...             ...             ...             ...   \n",
      "175   2020-06-09             3.0             3.0             3.0   \n",
      "176   2020-06-08             3.0             3.0             3.0   \n",
      "177   2020-06-07             3.0             3.0             3.0   \n",
      "178   2020-06-06             3.0             3.0             3.0   \n",
      "179   2020-06-05             3.0             3.0             3.0   \n",
      "\n",
      "     c1_school_clo4  c1_school_clo5  c1_school_clo6  c1_school_clo7  \\\n",
      "0               0.0             0.0             0.0             0.0   \n",
      "1               0.0             0.0             0.0             0.0   \n",
      "2               0.0             0.0             0.0             0.0   \n",
      "3               0.0             0.0             0.0             0.0   \n",
      "4               0.0             0.0             0.0             0.0   \n",
      "..              ...             ...             ...             ...   \n",
      "175             3.0             3.0             3.0             3.0   \n",
      "176             3.0             3.0             3.0             3.0   \n",
      "177             3.0             3.0             3.0             3.0   \n",
      "178             3.0             3.0             3.0             3.0   \n",
      "179             3.0             3.0             3.0             3.0   \n",
      "\n",
      "     c1_school_clo8  c1_school_clo9  ...  h6_facial_cover56  \\\n",
      "0               0.0             0.0  ...                2.0   \n",
      "1               0.0             0.0  ...                3.0   \n",
      "2               0.0             0.0  ...                3.0   \n",
      "3               0.0             0.0  ...                3.0   \n",
      "4               0.0             0.0  ...                3.0   \n",
      "..              ...             ...  ...                ...   \n",
      "175             3.0             3.0  ...                0.0   \n",
      "176             3.0             3.0  ...                0.0   \n",
      "177             3.0             3.0  ...                0.0   \n",
      "178             3.0             3.0  ...                0.0   \n",
      "179             3.0             3.0  ...                0.0   \n",
      "\n",
      "     h6_facial_cover57  h6_facial_cover58  h6_facial_cover59  \\\n",
      "0                  3.0                3.0                3.0   \n",
      "1                  3.0                3.0                3.0   \n",
      "2                  3.0                3.0                3.0   \n",
      "3                  3.0                3.0                3.0   \n",
      "4                  3.0                3.0                3.0   \n",
      "..                 ...                ...                ...   \n",
      "175                0.0                0.0                0.0   \n",
      "176                0.0                0.0                0.0   \n",
      "177                0.0                0.0                0.0   \n",
      "178                0.0                0.0                0.0   \n",
      "179                0.0                0.0                0.0   \n",
      "\n",
      "     h6_facial_cover60  Mobility_grocery_and_pharmacy  Mobility_parks  \\\n",
      "0                  3.0                        -20.143         -71.857   \n",
      "1                  3.0                        -21.429         -72.429   \n",
      "2                  3.0                        -22.143         -72.429   \n",
      "3                  3.0                        -22.286         -72.571   \n",
      "4                  3.0                        -23.000         -72.714   \n",
      "..                 ...                            ...             ...   \n",
      "175                0.0                        -40.286         -78.000   \n",
      "176                0.0                        -37.857         -77.000   \n",
      "177                0.0                        -40.286         -77.857   \n",
      "178                0.0                        -42.857         -79.286   \n",
      "179                0.0                        -47.000         -81.143   \n",
      "\n",
      "     Mobility_transit_stations  Mobility_residential  Mobility_workplaces  \n",
      "0                      -48.857                15.000              -22.571  \n",
      "1                      -49.714                15.429              -23.000  \n",
      "2                      -49.714                15.571              -23.429  \n",
      "3                      -50.000                15.714              -23.429  \n",
      "4                      -50.143                15.857              -23.571  \n",
      "..                         ...                   ...                  ...  \n",
      "175                    -70.000                27.143              -60.286  \n",
      "176                    -68.857                26.571              -58.286  \n",
      "177                    -69.857                26.857              -58.429  \n",
      "178                    -71.571                27.286              -59.286  \n",
      "179                    -74.143                28.000              -61.714  \n",
      "\n",
      "[180 rows x 726 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import os\n",
    "import numpy as np\n",
    "!pwd\n",
    "\n",
    "total_rows=180\n",
    "input_date=datetime.date(2020, 12, 1)\n",
    "dyn_df = pd.read_csv('data/dynamic.csv')\n",
    "reg=\"AFG\"\n",
    "lookback_days=60\n",
    "df=create_dataframe(lookback_days, total_rows, input_date,  dyn_df,  reg)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries = ['AFG', 'ARG', 'AUS', 'BGD', 'BEL', 'BRA', 'CAN', 'DNK', 'EGY', 'FRA','GHA','HKG','IND', 'IRL', 'ISR', 'ITA', 'JPN', 'KGZ', 'LTU','MEX', 'NAM','NZL', 'NGA', 'OMN', 'PER', \n",
    "#              'PRI', 'QAT', 'SAU', 'ZAF', 'KOR', 'THA', 'GBR', 'USA','ZMB']\n",
    "# # countries = ['AFG','ARG','AUS','BGD','CAN']\n",
    "countries = ['AUS','CAN', 'DNK','BRA', 'FRA','IND','ITA','QAT','SAU','EGY','MEX',\n",
    "             'KOR','USA','ZMB']\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "for reg in countries:\n",
    "    df = create_dataframe(lookback_days, total_rows, input_date,  dyn_df,  reg)\n",
    "    final_df = final_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 726)\n",
      "[0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(final_df.shape)\n",
    "\n",
    "final_df.to_csv(os.path.join('data', 'train_final_npi.csv'))\n",
    "final_df_np=final_df.to_numpy()\n",
    "print(final_df_np[0,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
