{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from dateutil.parser import parse \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = ['ABW','AFG','AGO','ALB','AND','ARE','ARG','AUS','AUT','AZE','BDI','BEL','BEN','BFA','BGD','BGR','BHR','BHS','BIH','BLR','BLZ','BMU','BOL','BRA','BRB','BRN','BTN','BWA','CAF','CAN','CHE','CHL','CHN','CIV','CMR','COD','COG','COL','COM','CPV','CRI','CUB','CYP','CZE','DEU','DJI','DMA','DNK','DOM','DZA','ECU','EGY','ERI','ESP','EST','ETH','FIN','FJI','FRA','FRO','GAB','GBR','GEO','GHA','GIN','GMB','GRC','GRL','GTM','GUM','GUY','HKG','HND','HRV','HTI','HUN','IDN','IND','IRL','IRN','IRQ','ISL','ISR','ITA','JAM','JOR','JPN','KAZ','KEN','KGZ','KHM','KOR','KWT','LAO','LBN','LBR','LBY','LKA','LSO','LTU','LUX','LVA','MAC','MAR','MCO','MDA','MDG','MEX','MLI','MMR','MNG','MOZ','MRT','MUS','MWI','MYS','NAM','NER','NGA','NIC','NLD','NOR','NPL','NZL','OMN','PAK','PAN','PER','PHL','PNG','POL','PRI','PRT','PRY','PSE','QAT','RKS','ROU','RUS','RWA','SAU','SDN','SEN','SGP','SLB','SLE','SLV','SMR','SOM','SRB','SSD','SUR','SVK','SVN','SWE','SWZ','SYC','SYR','TCD','TGO','THA','TJK','TKM','TLS','TTO','TUN','TUR','TWN','TZA','UGA','UKR','URY','USA','UZB','VEN','VIR','VNM','VUT','YEM','ZAF','ZMB','ZWE']\n",
    "filenames = [\"c1_school_closing.csv\", \"c2_workplace_closing.csv\", \"c3_cancel_public_events.csv\", \"c4_restrictions_on_gatherings.csv\", \"c5_close_public_transport.csv\", \"c6_stay_at_home_requirements.csv\", \"c7_movementrestrictions.csv\", \"c8_internationaltravel.csv\", \"confirmed_cases.csv\"]\n",
    "\n",
    "def dateConvertor(date):\n",
    "    dt = parse(date)\n",
    "    date = dt.strftime('%Y-%m-%d')\n",
    "    return date\n",
    "\n",
    "country_code2id = {}\n",
    "for i in range(len(country_codes)):\n",
    "    country_code2id[country_codes[i]] = i \n",
    "\n",
    "# date extraction\n",
    "npi_date = pd.DataFrame({})\n",
    "npi_date['Date'] = pd.read_csv(os.path.join('timeseries', filenames[0])).keys()[3:]\n",
    "npi_date['Date'] = npi_date['Date'].apply(dateConvertor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes = {} \n",
    "\n",
    "countries_to_extract = ['ITA','IND','USA','CHN','BRA','IRN','CAN','GBR',\n",
    "                        'FRA','ESP','BEL','DEU','NLD','MEX','TUR','SWE','ECU','RUS','PER','CHE'] # countries code for which you want data. \n",
    "index = [country_code2id[code] for code in countries_to_extract]\n",
    "\n",
    "##reading and processing the country-wise static data\n",
    "static_data = pd.read_csv(os.path.join('timeseries', 'Consolidated - Consolidated.csv')).T[2:][index].T.to_numpy()\n",
    "tmp = static_data[:,4:]\n",
    "#final static data = [20,6]\n",
    "final_static_data = np.concatenate((static_data[:,0:4],np.min(tmp,axis = -1).reshape(-1,1),\n",
    "                                   np.min(tmp,axis = -1).reshape(-1,1)),axis = -1).astype(np.float64)\n",
    "\n",
    "\n",
    "for file in filenames:\n",
    "    npi_df = pd.read_csv(os.path.join('timeseries', file)).T[3:]\n",
    "    npi_df['Date'] = npi_date['Date'].values\n",
    "    npi_df.set_index('Date', drop=True, inplace=True)\n",
    "    npi_df = npi_df[index] # selecting countries \n",
    "    npi_df = npi_df[64:335] # removing Jan, Feb and Dec data\n",
    "    for col in npi_df:\n",
    "        npi_df[col] = pd.to_numeric(npi_df[col], errors='coerce') # converting object to numeric \n",
    "    npi_df.interpolate(method='linear', inplace=True) # interpolate missing values \n",
    "    dataframes[file[:-4]] = npi_df\n",
    "   \n",
    "    \n",
    "    \n",
    "    if(file[:-4]=='confirmed_cases'):\n",
    "#         npi_df = pd.read_csv(os.path.join('timeseries', file))\n",
    "#         print(npi_df)\n",
    "        npi_df = pd.read_csv(os.path.join('timeseries', file)).T[3:]\n",
    "        npi_df['Date'] = npi_date['Date'].values\n",
    "        npi_df.set_index('Date', drop=True, inplace=True)\n",
    "        npi_df = npi_df[index] # selecting countries \n",
    "#         npi_df = npi_df[64:335] # removing Jan, Feb and Dec data\n",
    "        for col in npi_df:\n",
    "            npi_df[col] = pd.to_numeric(npi_df[col], errors='coerce')\n",
    "        npi_df = npi_df.interpolate(method='linear') # interpolate missing values     \n",
    "        npi_df = npi_df.rolling(7).mean()\n",
    "        \n",
    "        npi_df = 100*npi_df.diff()/npi_df\n",
    "        npi_df = npi_df[64:335] # removing Jan, Feb and Dec data\n",
    "        \n",
    "        \n",
    "        \n",
    "#         npi_df.interpolate(method='linear', inplace=True) # interpolate missing values     \n",
    "        dataframes['growth_rate'] = npi_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(attributes, history, date):\n",
    "    index = dataframes['c1_school_closing'].index.get_loc(date)\n",
    "    if(history>index):\n",
    "        print('Not sufficient history')\n",
    "        sys.exit()\n",
    "    data = []\n",
    "    for att in attributes:\n",
    "        temp = dataframes[att].iloc[index-history:index].values\n",
    "        if(len(data)==0):\n",
    "            data = np.asarray(temp)\n",
    "        else:\n",
    "            data = np.dstack((data, temp))\n",
    "\n",
    "#      #without including static data       \n",
    "#     x = torch.from_numpy(data).to(dtype=torch.double).permute(1,0,2).view(len(countries_to_extract),-1)\n",
    "    \n",
    "    #including static data\n",
    "    x = torch.cat((torch.from_numpy(data).to(dtype=torch.double).permute(1,0,2).view(len(countries_to_extract),-1),\n",
    "                   torch.from_numpy(final_static_data).to(dtype=torch.double)),dim = -1)\n",
    "    \n",
    "    y = torch.from_numpy(dataframes['growth_rate'].iloc[index].values).to(dtype=torch.double)\n",
    "    \n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"c1_school_closing\", \"c2_workplace_closing\", \"c3_cancel_public_events\", \"c4_restrictions_on_gatherings\", \"c5_close_public_transport\", \"c6_stay_at_home_requirements\", \"c7_movementrestrictions\", \"c8_internationaltravel\", \"confirmed_cases\"]\n",
    "history = 21\n",
    "dates = npi_date['Date'][85:335].values #(total allowed range for dates)\n",
    "x,y = readData(attributes=attributes, history=history, date=dates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 195])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "# x = [20,195] y = [20]\n",
    "    # 195 = history*len(attributes)+dimension_of_static data\n",
    "    # 20 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
